// iree_ort_utils.cc - ORT/IREE type conversion and tensor utilities.

#include "iree_ort_utils.h"

#include <numeric>

#include "iree/hal/buffer_transfer.h"
#include "iree/hal/buffer_view_util.h"

namespace iree_onnx_ep {

// ============================================================================
// Element Type Mapping
// ============================================================================

iree_hal_element_type_t OnnxToIreeElementType(
    ONNXTensorElementDataType onnx_type) {
  switch (onnx_type) {
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT:
      return IREE_HAL_ELEMENT_TYPE_FLOAT_32;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_DOUBLE:
      return IREE_HAL_ELEMENT_TYPE_FLOAT_64;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT16:
      return IREE_HAL_ELEMENT_TYPE_FLOAT_16;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_BFLOAT16:
      return IREE_HAL_ELEMENT_TYPE_BFLOAT_16;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_INT8:
      return IREE_HAL_ELEMENT_TYPE_SINT_8;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_INT16:
      return IREE_HAL_ELEMENT_TYPE_SINT_16;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_INT32:
      return IREE_HAL_ELEMENT_TYPE_SINT_32;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_INT64:
      return IREE_HAL_ELEMENT_TYPE_SINT_64;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT8:
      return IREE_HAL_ELEMENT_TYPE_UINT_8;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT16:
      return IREE_HAL_ELEMENT_TYPE_UINT_16;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT32:
      return IREE_HAL_ELEMENT_TYPE_UINT_32;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT64:
      return IREE_HAL_ELEMENT_TYPE_UINT_64;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_BOOL:
      return IREE_HAL_ELEMENT_TYPE_BOOL_8;
    default:
      return IREE_HAL_ELEMENT_TYPE_NONE;
  }
}

ONNXTensorElementDataType IreeToOnnxElementType(
    iree_hal_element_type_t iree_type) {
  switch (iree_type) {
    case IREE_HAL_ELEMENT_TYPE_FLOAT_32:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT;
    case IREE_HAL_ELEMENT_TYPE_FLOAT_64:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_DOUBLE;
    case IREE_HAL_ELEMENT_TYPE_FLOAT_16:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT16;
    case IREE_HAL_ELEMENT_TYPE_BFLOAT_16:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_BFLOAT16;
    case IREE_HAL_ELEMENT_TYPE_SINT_8:
    case IREE_HAL_ELEMENT_TYPE_INT_8:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_INT8;
    case IREE_HAL_ELEMENT_TYPE_SINT_16:
    case IREE_HAL_ELEMENT_TYPE_INT_16:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_INT16;
    case IREE_HAL_ELEMENT_TYPE_SINT_32:
    case IREE_HAL_ELEMENT_TYPE_INT_32:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_INT32;
    case IREE_HAL_ELEMENT_TYPE_SINT_64:
    case IREE_HAL_ELEMENT_TYPE_INT_64:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_INT64;
    case IREE_HAL_ELEMENT_TYPE_UINT_8:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT8;
    case IREE_HAL_ELEMENT_TYPE_UINT_16:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT16;
    case IREE_HAL_ELEMENT_TYPE_UINT_32:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT32;
    case IREE_HAL_ELEMENT_TYPE_UINT_64:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT64;
    case IREE_HAL_ELEMENT_TYPE_BOOL_8:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_BOOL;
    default:
      return ONNX_TENSOR_ELEMENT_DATA_TYPE_UNDEFINED;
  }
}

size_t OnnxElementTypeSize(ONNXTensorElementDataType type) {
  switch (type) {
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_BOOL:
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_INT8:
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT8:
      return 1;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT16:
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_BFLOAT16:
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_INT16:
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT16:
      return 2;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT:
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_INT32:
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT32:
      return 4;
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_DOUBLE:
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_INT64:
    case ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT64:
      return 8;
    default:
      return 0;
  }
}

// ============================================================================
// Buffer/Tensor Conversion
// ============================================================================

// TODO: The implementation of these functions is a bit wrong. We are ASSUMING
// that the ort tensors are on the host and the iree tensors will live on the
// device. We should move to checking where the ort tensor lives and copying
// the data if needed.

OrtStatus* OrtTensorToIreeBufferView(const Ort::ConstValue& ort_value,
                                     iree_hal_device_t* device,
                                     iree_hal_allocator_t* allocator,
                                     iree_allocator_t /*host_allocator*/,
                                     iree_hal_buffer_view_t** out_buffer_view) {
  *out_buffer_view = nullptr;

  // Get tensor info from ORT.
  auto type_info = ort_value.GetTensorTypeAndShapeInfo();
  auto onnx_dtype = type_info.GetElementType();
  auto shape = type_info.GetShape();

  // Convert element type.
  iree_hal_element_type_t iree_dtype = OnnxToIreeElementType(onnx_dtype);
  if (iree_dtype == IREE_HAL_ELEMENT_TYPE_NONE) {
    return Ort::Status("IREE EP: Unsupported element type", ORT_NOT_IMPLEMENTED)
        .release();
  }

  // Get raw data pointer.
  const void* data = ort_value.GetTensorRawData();
  size_t byte_size = CalculateTensorByteSize(shape, onnx_dtype);

  // Convert shape to IREE format.
  std::vector<iree_hal_dim_t> iree_shape(shape.begin(), shape.end());

  // Set up buffer parameters for device-local memory.
  iree_hal_buffer_params_t buffer_params = {};
  buffer_params.type = IREE_HAL_MEMORY_TYPE_DEVICE_LOCAL;
  buffer_params.usage = IREE_HAL_BUFFER_USAGE_DEFAULT;

  // Allocate buffer and copy data.
  IREE_ORT_RETURN_IF_ERROR(iree_hal_buffer_view_allocate_buffer_copy(
      device, allocator, iree_shape.size(), iree_shape.data(), iree_dtype,
      IREE_HAL_ENCODING_TYPE_DENSE_ROW_MAJOR, buffer_params,
      iree_make_const_byte_span(data, byte_size), out_buffer_view));

  return nullptr;
}

OrtStatus* IreeBufferViewToOrtTensor(iree_hal_buffer_view_t* buffer_view,
                                     Ort::UnownedValue ort_value,
                                     iree_hal_device_t* device) {
  // Get buffer from view.
  iree_hal_buffer_t* buffer = iree_hal_buffer_view_buffer(buffer_view);
  iree_device_size_t byte_length =
      iree_hal_buffer_view_byte_length(buffer_view);

  // Get destination pointer from ORT tensor.
  void* dest_data = ort_value.GetTensorMutableRawData();

  // Transfer data from device to host.
  IREE_ORT_RETURN_IF_ERROR(iree_hal_device_transfer_d2h(
      device, buffer,
      /*source_offset=*/0, dest_data, byte_length,
      IREE_HAL_TRANSFER_BUFFER_FLAG_DEFAULT, iree_infinite_timeout()));

  return nullptr;
}

std::vector<int64_t> GetBufferViewShape(iree_hal_buffer_view_t* buffer_view) {
  iree_host_size_t rank = iree_hal_buffer_view_shape_rank(buffer_view);
  const iree_hal_dim_t* dims = iree_hal_buffer_view_shape_dims(buffer_view);

  std::vector<int64_t> shape(rank);
  for (iree_host_size_t i = 0; i < rank; ++i) {
    shape[i] = static_cast<int64_t>(dims[i]);
  }
  return shape;
}

size_t CalculateTensorByteSize(const std::vector<int64_t>& shape,
                               ONNXTensorElementDataType element_type) {
  if (shape.empty()) {
    return OnnxElementTypeSize(element_type);  // Scalar.
  }

  size_t num_elements = std::accumulate(shape.begin(), shape.end(), size_t{1},
                                        std::multiplies<size_t>());
  return num_elements * OnnxElementTypeSize(element_type);
}

}  // namespace iree_onnx_ep
